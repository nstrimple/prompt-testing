{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29297395",
   "metadata": {},
   "source": [
    "# Creating a conditional chat \n",
    "*The goal here is to make a chat that can fill out a for utilizing a chat with a user*\n",
    "\n",
    "First step is to download the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc7e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from string import Template\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08533d88",
   "metadata": {},
   "source": [
    "### Set up your key parameters\n",
    "Response limiting is to avoid over requesting the api if you are utilizing the trial version of the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03f4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "model = \"gpt-3.5-turbo-0613\"\n",
    "response_limit = 4\n",
    "response_number = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79d911",
   "metadata": {},
   "source": [
    "### Generic model completion function with functionality to support a function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897742cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_completion(\n",
    "    messages, \n",
    "    functions = None, \n",
    "    function_call = \"none\", \n",
    "    response_limit = response_limit, \n",
    "    response_number = response_number):\n",
    "    if response_number % response_limit == 0:\n",
    "        time.sleep(30)\n",
    "    if functions == None:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model = model,\n",
    "            messages = messages\n",
    "        )\n",
    "    else:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            functions = functions,\n",
    "            function_call = function_call,\n",
    "            temperature = 0\n",
    "        )\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    if message.get(\"function_call\"):\n",
    "        return json.loads(message[\"function_call\"][\"arguments\"])\n",
    "    else:\n",
    "        return message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2359cc83",
   "metadata": {},
   "source": [
    "### Helper functions to support the chain and handle missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4a6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_formation_prompt = \"\"\"Your task is to ask a user for information about the following fields delimited by \\\n",
    "triple back ticks.\n",
    "``` \n",
    "${fields}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def key_search(key, func):\n",
    "    if type(func) == str:\n",
    "        t = 0\n",
    "    elif type(func) == list:\n",
    "        for i in func:\n",
    "            key_search(key, i)\n",
    "    elif key not in func.keys():\n",
    "        for f in func.keys():\n",
    "            val = key_search(key, func[f])\n",
    "            if val != None:\n",
    "                return val\n",
    "    else:\n",
    "        return func[key]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e33cf",
   "metadata": {},
   "source": [
    "### Function to run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99f7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_response_chain(\n",
    "    starting_prompt : str, \n",
    "    functions : list,\n",
    "    function_name : str, \n",
    "    needed_fields : list, \n",
    "    response_number = response_number) -> dict:\n",
    "    complete = False\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : starting_prompt\n",
    "        }\n",
    "    ]\n",
    "    f_id = 0\n",
    "    for idx, f in enumerate(functions):\n",
    "        if f.get(\"name\") == function_name:\n",
    "            f_id = idx\n",
    "    while not complete:\n",
    "        function_call = {\"name\" : function_name}\n",
    "        response = get_model_completion(messages, functions, function_call, response_number = response_number)\n",
    "        response_number += 1\n",
    "        missing = []\n",
    "        for i in needed_fields:\n",
    "            if i not in list(response.keys()):\n",
    "                missing.append(i)\n",
    "            elif response[i] == '-1':\n",
    "                missing.append(i)\n",
    "        if len(missing) == 0:\n",
    "            complete = True\n",
    "            return response\n",
    "        fields = []\n",
    "        for m in missing:\n",
    "            desc = key_search(m, functions[f_id])\n",
    "            fields.append(f\"{m} : {desc}\")\n",
    "            \n",
    "        fields = \"\\n\".join(fields)\n",
    "        prompt_template = Template(question_formation_prompt)\n",
    "        q_prompt = prompt_template.substitute(fields = fields)\n",
    "        q_message = [\n",
    "            {\n",
    "                \"role\" : \"system\",\n",
    "                \"content\" : q_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : \"What do you need to know\"\n",
    "            }\n",
    "        ]\n",
    "        q_response = get_model_completion(q_message, response_number = response_number)\n",
    "        response_number += 1\n",
    "        in_ = input(f\"Model: {q_response} \\n\\nUser Input: \")\n",
    "        print('\\n')\n",
    "        messages.append({\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : in_\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c90e6",
   "metadata": {},
   "source": [
    "### Function structure\n",
    "Important notes:\n",
    "1. Only include fields you are ok with the model guessing on in required\n",
    "2. Fields that you are not ok with guesses make it `if not provided return -1`\n",
    "3. For enums if this is not a field you are ok with a guess include -1 in the enum values. Make sure that it is the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8741eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\" : \"jira_api_call\",\n",
    "        \"description\" : \"\"\"This is a wrapper on the jira api that takes content from the user and writes /\n",
    "        to their jira environment\"\"\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" : {\n",
    "                \"title\" : {\n",
    "                    \"type\" : \"string\",\n",
    "                    \"description\" : \"\"\"This is the headline title of the jira story. This should describe the \\\n",
    "                    story in about 5 to 10 words\"\"\"\n",
    "                },\n",
    "                \"description\" : {\n",
    "                    \"type\" : \"string\",\n",
    "                    \"description\" : \"\"\"This is the series of instructions that the engineering team will use \\\n",
    "                    to determine the scope of the story and how to complete the work to implement it\"\"\"\n",
    "                },\n",
    "                \"owner\" : {\n",
    "                    \"type\" : \"string\",\n",
    "                    \"description\" : \"\"\"This is the product manager that will own this task. Do not guess. Do not \\\n",
    "                    make something up. If not provided return -1.\"\"\",\n",
    "                    \"enum\" : [\"Nelson Strimple\", \"Taina Felix\", \"LeBron James\", \"-1\"]\n",
    "                },\n",
    "                \"deadline\" : {\n",
    "                    \"type\" : \"string\",\n",
    "                    \"description\" : f\"\"\"This is the date that the project has to be completed by. It has \\\n",
    "                    to be after {datetime.now().date()}. It is to be formated year-month-day. If not provided \\\n",
    "                    return -1\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"required\" : [\"title\", \"description\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Running a prompt that will leave out deadline and owner on purpose\n",
    "test_prompt = \"\"\"\n",
    "You are product management assistant. Your role is to chat about new features /\n",
    "or products that they want to produce.  You will then format that information to use the function /\n",
    "jira_api_call. The user input will be delimited by triple back ticks.\n",
    "\n",
    "```\n",
    "Create a new api endpoint that will take in user input, call a large language, and then return /\n",
    "the model output to a user.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "elements = [\"title\", \"description\", \"owner\", \"deadline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97795e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: I need to know the following information:\n",
      "\n",
      "- Who will be the owner of this task? \n",
      "- What is the deadline for completing the project? \n",
      "\n",
      "User Input: Taina will be the owner\n",
      "\n",
      "\n",
      "Model: Please provide the deadline for the project. \n",
      "\n",
      "User Input: End of September\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = function_response_chain(test_prompt, functions, \"jira_api_call\", elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801a565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"title\": \"Create a new API endpoint for language translation\",\n",
      " \"description\": \"Develop a new API endpoint that will take in user input, call a large language model, and return the model output to the user.\",\n",
      " \"owner\": \"Taina Felix\",\n",
      " \"deadline\": \"2023-09-30\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(res, indent = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
